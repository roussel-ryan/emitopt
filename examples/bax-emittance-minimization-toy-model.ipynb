{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ac8fe9",
   "metadata": {},
   "source": [
    "# Emittance minimization using Xopt with BAXGenerator running algorithm ScipyMinimizeEmittance\n",
    "In this notebook we demonstrate the use of Xopt to perform Bayesian Algorithm Execution (BAX) as a means of minimizing the emittance described by a simple optical beam size model. BAX is a generalization of Bayesian Optimization that seeks to acquire observations that provide our model with maximal information about our property of interest. In this example, our property of interest is the minimal emittance and its location in tuning-parameter-space. See https://arxiv.org/pdf/2209.04587.pdf for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2666c7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2005f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\Dylan\\\\SLAC') #parent directory containing emitopt module\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from xopt import Xopt\n",
    "from xopt.vocs import VOCS\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "\n",
    "from xopt.evaluator import Evaluator\n",
    "\n",
    "from emitopt.utils import (post_path_emit_squared,\n",
    "                           compute_emits,\n",
    "                           get_meas_scan_inputs_from_tuning_configs,\n",
    "                           get_valid_emittance_samples)\n",
    "from emitopt.sampling import draw_product_kernel_post_paths\n",
    "from emitopt.algorithms import ScipyMinimizeEmittance\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d378d",
   "metadata": {},
   "source": [
    "# Use CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9d65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "if False:\n",
    "    torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "    use_cuda = True\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "    use_cuda = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f6014",
   "metadata": {},
   "source": [
    "# Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9323010",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 3 #number of input dimensions\n",
    "noise = False #whether to add noise to the ground-truth beam size function outputs\n",
    "meas_dim = 1 #input dimension for measurement parameter\n",
    "n_obs_init = 3 #number of random initial observations for GP model\n",
    "n_samples = 10 #number of posterior samples for BAX\n",
    "n_iter = 400 #number of optimization steps for Xopt to take (after acquiring random initial data)\n",
    "rand_seed = 2\n",
    "\n",
    "#random seeds for reproducibility \n",
    "torch.manual_seed(rand_seed)\n",
    "np.random.seed(rand_seed) #only affects initial random observations through Xopt\n",
    "random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87785524",
   "metadata": {},
   "source": [
    "# Build test function from single-quadrupole optical beam size model \n",
    "Here we define a simple ground-truth beam size function for our optimization problem, where we attempt to find the location in tuning parameter space with minimal emittance. Note that the function \"test_func\" used to evaluate the ground-truth beam size function takes a dictionary as input and returns a dictionary as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73bcfe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-Truth Minimum Emittance: 1.9364916731037083\n"
     ]
    }
   ],
   "source": [
    "# define test functions\n",
    "var_names = ['x' + str(i) for i in range(ndim)]\n",
    "meas_param = var_names[meas_dim]\n",
    "\n",
    "beam_energy = 0.135\n",
    "distance = torch.tensor(2.26).double()\n",
    "q_len = torch.tensor(0.108).double()\n",
    "s11 = torch.tensor(3e-6).double()\n",
    "s12 = torch.tensor(1.5e-6).double()\n",
    "s22 = torch.tensor(2e-6).double()\n",
    "gt_min_emit = torch.sqrt(s11 * s22 - s12 ** 2)*1e6\n",
    "print('Ground-Truth Minimum Emittance:', gt_min_emit.item())\n",
    "\n",
    "\n",
    "\n",
    "def beam_size_squared(k, d, l, s11, s12, s22):\n",
    "    return (\n",
    "        (1.0 + k * d * l) ** 2 * s11 + 2.0 * (1.0 + d * l * k) * d * s12 + d ** 2 * s22\n",
    "    )\n",
    "    \n",
    "def toy_beam_size_squared_nd(x, meas_dim, noise=noise):\n",
    "    \n",
    "    tuning_dims = list(range(x.shape[-1]))\n",
    "    tuning_dims.remove(meas_dim)\n",
    "    emit = torch.sqrt(s11 * s22 - s12 ** 2)\n",
    "    bss = ((1 + torch.sum(x[:,tuning_dims]**2, dim=1) )* beam_size_squared(x[:,meas_dim], distance, q_len, s11, s12, s22)).reshape(-1,1) \n",
    "#     bss = ( (1 + 9.*(1 - torch.exp(-0.5*(50.*torch.sum(x[:,tuning_dims]**2, dim=1))) ) ) * \n",
    "#            beam_size_squared(x[:,meas_dim], distance, q_len, s11, s12, s22)\n",
    "#           ).reshape(-1,1) \n",
    "    bss *= 1.e6\n",
    "    if noise:\n",
    "        bss *= (1 + 0.05*torch.rand_like(bss))      \n",
    "    return bss\n",
    "\n",
    "def toy_emit_nd(X_tuning):\n",
    "#     return ( 1 + 9.*(1 - torch.exp(-0.5*(50.*torch.sum(X_tuning**2, dim=1))) ) ) * gt_min_emit\n",
    "    return (1 + torch.sum(X_tuning**2, dim=1) ) * gt_min_emit\n",
    "\n",
    "def test_func(input_dict):\n",
    "    x = torch.tensor(input_dict[meas_param]).reshape(-1,1)\n",
    "    for key in input_dict.keys():\n",
    "        if key is not meas_param:\n",
    "            x = torch.cat((x, torch.tensor(input_dict[key]).reshape(-1,1)), dim=1)\n",
    "    return {'y': float(toy_beam_size_squared_nd(x, 0).squeeze().cpu().numpy()),\n",
    "           'emittance': float(toy_emit_nd(x[:,1:]).squeeze().cpu().numpy())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2c09a",
   "metadata": {},
   "source": [
    "# Construct vocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dfbf20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable_names = ['x0', 'x1', 'x2']\n",
      "meas_param = 'x1'\n",
      "domain =\n",
      " [[ -3.   1.]\n",
      " [-40.  40.]\n",
      " [ -3.   1.]]\n"
     ]
    }
   ],
   "source": [
    "variables = {var_name: [-3,1] for var_name in var_names}\n",
    "variables[meas_param] = [-40,40] #overwrite bounds for measurement parameter to capture minimum of single-quadrupole optical model\n",
    "\n",
    "#construct vocs\n",
    "vocs = VOCS(\n",
    "    variables = variables,\n",
    "    objectives = {'y':\"MINIMIZE\"}\n",
    ")\n",
    "\n",
    "print('variable_names =', vocs.variable_names)\n",
    "print('meas_param =', \"'\" + meas_param + \"'\")\n",
    "print('domain =\\n', vocs.bounds.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4651f47",
   "metadata": {},
   "source": [
    "# Prepare generator options.\n",
    "In this example, we use a specialty covariance module (Matern x Quadratic kernel) for our beam size model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02894212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import MaternKernel, PolynomialKernel, ScaleKernel\n",
    "from gpytorch.priors.torch_priors import GammaPrior\n",
    "\n",
    "from xopt.generators.bayesian.models.standard import StandardModelConstructor\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "from emitopt.algorithms import ScipyMinimizeEmittance\n",
    "\n",
    "# prepare custom covariance module\n",
    "tuning_dims = list(range(vocs.n_variables))\n",
    "tuning_dims.remove(meas_dim)\n",
    "covar_module = MaternKernel(active_dims=tuning_dims, lengthscale_prior=GammaPrior(3.0, 6.0)) * PolynomialKernel(\n",
    "    power=2, active_dims=[meas_dim]\n",
    ")\n",
    "scaled_covar_module = ScaleKernel(covar_module, outputscale_prior=GammaPrior(2.0, 0.15))   \n",
    "\n",
    "# prepare options for Xopt generator\n",
    "covar_module_dict = {'y': scaled_covar_module}\n",
    "\n",
    "model_constructor = StandardModelConstructor(covar_modules=covar_module_dict, use_low_noise_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "724571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.numerical_optimizer import LBFGSOptimizer\n",
    "numerical_optimizer = LBFGSOptimizer(\n",
    "                                    n_raw_samples=20,\n",
    "                                    n_restarts=10,\n",
    "                                    max_iter=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd586df8",
   "metadata": {},
   "source": [
    "# Construct generator, evaluator, Xopt objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7623bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare Algorithm\n",
    "from emitopt.utils import get_quad_strength_conversion_factor\n",
    "# scale_factor = get_quad_strength_conversion_factor(E=beam_energy, q_len=q_len)\n",
    "scale_factor = 1.\n",
    "algo_kwargs = {\n",
    "        'scale_factor': scale_factor,\n",
    "        'q_len': q_len,\n",
    "        'distance': distance,\n",
    "        'n_samples': n_samples,\n",
    "        'meas_dim': meas_dim,\n",
    "        'n_steps_measurement_param': 3,\n",
    "        'n_steps_exe_paths':  11}\n",
    "algo = ScipyMinimizeEmittance(**algo_kwargs)\n",
    "\n",
    "#construct BAX generator\n",
    "generator = BaxGenerator(vocs=vocs, \n",
    "                         model_constructor=model_constructor, \n",
    "                         numerical_optimizer=numerical_optimizer,\n",
    "                         algorithm=algo, \n",
    "                         use_cuda=use_cuda)\n",
    "\n",
    "#construct evaluator\n",
    "evaluator = Evaluator(function=test_func)\n",
    "\n",
    "#construct Xopt optimizer\n",
    "optimizer = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae84fc5",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3553f6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "      <th>emittance</th>\n",
       "      <th>xopt_runtime</th>\n",
       "      <th>xopt_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.743980</td>\n",
       "      <td>5.174209</td>\n",
       "      <td>0.181405</td>\n",
       "      <td>64.916418</td>\n",
       "      <td>3.072077</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.896295</td>\n",
       "      <td>6.370576</td>\n",
       "      <td>-1.477084</td>\n",
       "      <td>187.781443</td>\n",
       "      <td>7.717155</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.198650</td>\n",
       "      <td>13.573214</td>\n",
       "      <td>-0.198619</td>\n",
       "      <td>235.887869</td>\n",
       "      <td>4.795162</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0         x1        x2           y  emittance  xopt_runtime  \\\n",
       "1 -0.743980   5.174209  0.181405   64.916418   3.072077      0.003046   \n",
       "2  0.896295   6.370576 -1.477084  187.781443   7.717155      0.000289   \n",
       "3 -1.198650  13.573214 -0.198619  235.887869   4.795162      0.000226   \n",
       "\n",
       "   xopt_error  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call X.random_evaluate() to generate random initial points and evaluate on test_func\n",
    "optimizer.random_evaluate(n_obs_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79bf85b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8963,  6.3706, -1.4771]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(optimizer.data[vocs.variable_names].iloc[-2].to_numpy().reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8a54961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample validity rate: tensor([0.0484])\n",
      "Iteration: 1 / 400\n",
      "acq func _n_evals: 82\n",
      "This iteration took: 1.795408010482788 seconds.\n",
      "\n",
      "Iteration: 2 / 400\n",
      "Scipy failed to find at least 3 physically valid solutions.\n",
      "acq func _n_evals: 98\n",
      "This iteration took: 3.3411521911621094 seconds.\n",
      "\n",
      "Iteration: 3 / 400\n",
      "acq func _n_evals: 88\n",
      "This iteration took: 2.098541498184204 seconds.\n",
      "\n",
      "Iteration: 4 / 400\n",
      "acq func _n_evals: 94\n",
      "This iteration took: 1.3999180793762207 seconds.\n",
      "\n",
      "Iteration: 5 / 400\n",
      "acq func _n_evals: 72\n",
      "This iteration took: 1.921863317489624 seconds.\n",
      "\n",
      "Iteration: 6 / 400\n",
      "Scipy failed to find at least 3 physically valid solutions.\n",
      "acq func _n_evals: 102\n",
      "This iteration took: 1.76363205909729 seconds.\n",
      "\n",
      "Iteration: 7 / 400\n",
      "Scipy failed to find at least 3 physically valid solutions.\n",
      "acq func _n_evals: 80\n",
      "This iteration took: 1.3320424556732178 seconds.\n",
      "\n",
      "Iteration: 8 / 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "beam_size_models = {}\n",
    "\n",
    "#get initial emittance prediction at ground truth optimum\n",
    "beam_size_model = optimizer.generator.train_model().models[0]\n",
    "\n",
    "\n",
    "#get mean-predicted optimal tuning config and eval predicted emits at this location in tuning parameter space\n",
    "algo = optimizer.generator.algorithm\n",
    "X_tuned, emits_at_target_valid, svr = algo.mean_output(beam_size_model, \n",
    "                                                                                     torch.tensor(vocs.bounds), \n",
    "                                                                                     num_restarts=10)\n",
    "\n",
    "\n",
    "plt.hist(emits_at_target_valid.flatten().cpu(), density=True)\n",
    "plt.xlabel('Predicted Optimal Emittance')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.show()\n",
    "print('sample validity rate:', svr)\n",
    "\n",
    "for i in range(1, n_iter+1):\n",
    "\n",
    "    print('Iteration:', i, '/', n_iter)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # call X.step() to generate a random initial point and evaluate on test_func\n",
    "    optimizer.step()    \n",
    "\n",
    "    \n",
    "    #extract GP model\n",
    "    beam_size_model = optimizer.generator.model.models[0]\n",
    "    \n",
    "    #extract and store algorithm results for this iteration\n",
    "    results[i] = optimizer.generator.algorithm_results\n",
    "    beam_size_models[i] = beam_size_model\n",
    "    \n",
    "    #get mean-predicted optimal tuning config and eval predicted emits at this location in tuning parameter space\n",
    "    algo = optimizer.generator.algorithm\n",
    "#     X_tuned, emits_at_target_valid, svr = algo.mean_output(beam_size_model,\n",
    "#                                                          torch.tensor(vocs.bounds),\n",
    "#                                                          num_restarts=10)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('This iteration took:', end-start, 'seconds.\\n')\n",
    "\n",
    "#     if i % 5 == 0:\n",
    "#         plt.hist(emits_at_target_valid.flatten().cpu(), density=True)\n",
    "#         plt.xlabel('Predicted Optimal Emittance')\n",
    "#         plt.ylabel('Probability Density')\n",
    "#         plt.show()\n",
    "#         print('sample validity rate:', svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d344f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "acq = optimizer.generator.get_acquisition(optimizer.generator.model)\n",
    "end = time.time()\n",
    "print('get_acquisition took', end-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6c67e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from botorch.optim.optimize import optimize_acqf\n",
    "# start = time.time()\n",
    "# for i in range(1):\n",
    "#     res = optimize_acqf(acq_function=acq,\n",
    "#                         bounds=torch.tensor(vocs.bounds),\n",
    "#                         q=1,\n",
    "#                         num_restarts=50,\n",
    "#                         raw_samples=50,\n",
    "#                         options={'maxiter':100}\n",
    "#                        )\n",
    "# end = time.time()\n",
    "# print('optimize_acqf took', end-start, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3181749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acq = optimizer.generator.get_acquisition(optimizer.generator.model)\n",
    "\n",
    "# last_acq = np.vstack(data_all[0].iloc[-1][list(vocs.variable_data([vocs.random_inputs()], '').keys())].values[:]).astype(float)\n",
    "# last_acq = torch.tensor(last_acq).reshape(1,-1)\n",
    "\n",
    "# last_acq = res[0]\n",
    "last_acq = torch.tensor(optimizer.data[vocs.variable_names].iloc[-1].to_numpy().reshape(1,-1))\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim)\n",
    "    \n",
    "fig.set_size_inches(3*(ndim), 3)\n",
    "\n",
    "for scan_dim in range(ndim):\n",
    "    X_scan = last_acq.repeat(100,1)\n",
    "#     ls = torch.linspace(*vocs.bounds.T[scan_dim],100)\n",
    "    ls = torch.linspace(last_acq[0,scan_dim]-1,last_acq[0,scan_dim]+1,100)\n",
    "\n",
    "    X_scan[:,scan_dim] = ls\n",
    "\n",
    "    acq_scan = torch.tensor([acq(X.reshape(1,-1)) for X in X_scan]).reshape(-1)\n",
    "    \n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "    ax.plot(ls.cpu(), acq_scan.detach().cpu())\n",
    "    ax.axvline(last_acq[0,scan_dim].cpu(), c='r', label='Acquisition Result')\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel('Input ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('Acquisition Function')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ffbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import plot_sample_optima_convergence_inputs\n",
    "plot_sample_optima_convergence_inputs(results, show_valid_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c512cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import plot_sample_optima_convergence_emits\n",
    "plot_sample_optima_convergence_emits(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177de67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import plot_valid_emit_prediction_at_x_tuning\n",
    "\n",
    "x_tuned = torch.mean(results[n_iter]['x_stars_all'], dim=0, keepdim=True)\n",
    "print('x_tuned =', x_tuned)\n",
    "plot_valid_emit_prediction_at_x_tuning(beam_size_model, \n",
    "                                       x_tuned, \n",
    "                                       scale_factor = algo_kwargs['scale_factor'],\n",
    "                                       q_len = algo_kwargs['q_len'],\n",
    "                                       distance = algo_kwargs['distance'],\n",
    "                                       bounds = vocs.bounds,\n",
    "                                       meas_dim = algo_kwargs['meas_dim'],\n",
    "                                       n_samples = 10000,\n",
    "                                       n_steps_quad_scan = 10\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057a01f5",
   "metadata": {},
   "source": [
    "# Plot some beam size surface samples from our current model and do a scan of the predicted emittance as a function of our single tuning parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d25716",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ndim==2:\n",
    "    \n",
    "    device = torch.tensor(1).device\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, subplot_kw={\"projection\": \"3d\"})\n",
    "    fig.set_size_inches(15,10)\n",
    "\n",
    "    ax = axs[0]\n",
    "\n",
    "    for s in range(3):\n",
    "\n",
    "        # plot first 3 beam size surface samples\n",
    "        xlin, ylin = torch.arange(-3,1,0.05), torch.arange(-40,40, 1.)\n",
    "        X, Y = torch.meshgrid(xlin, ylin)\n",
    "        XY = torch.cat((X.reshape(-1,1), Y.reshape(-1,1)), dim=1)\n",
    "        print(XY.shape)\n",
    "        Z = optimizer.generator.algorithm_results['post_paths_cpu'](XY)[s].reshape(X.shape).detach()\n",
    "        cmap='viridis'\n",
    "        surf = ax.plot_surface(Y, X, Z, cmap=cmap,\n",
    "                               linewidth=0, antialiased=True, alpha=0.3, rasterized=True)\n",
    "\n",
    "        # add orange parabolic highlights\n",
    "        ax.plot(Y[0,:].numpy(), Z[0,:].numpy(), zs=X[0,0].item(), zdir='y', c='C1', lw=2, zorder=10)\n",
    "        ax.plot(Y[int(len(Z[0,:])/2),:].numpy(), Z[int(len(Z[0,:])/2),:].numpy(), zs=X[int(len(Z[0,:])/2),0].item(), zdir='y', c='C1', lw=2)\n",
    "        ax.plot(Y[-1,:].numpy(), Z[-1,:].numpy(), zs=X[-1,0].item(), zdir='y', c='C1', lw=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # plot initial observations\n",
    "    x0 = torch.tensor(optimizer.data['x0'].values)[:n_obs_init]\n",
    "    x1 = torch.tensor(optimizer.data['x1'].values)[:n_obs_init]\n",
    "    y = torch.tensor([item.item() for item in optimizer.data['y'].values])[:n_obs_init]\n",
    "    ax.scatter(x1.flatten(), x0.flatten(), y.flatten(), marker='o', c='C0', alpha=1, s=80, label='Random (Initial) Observations', zorder=15)\n",
    "\n",
    "    # plot bax observations\n",
    "    x0 = torch.tensor(optimizer.data['x0'].values)[n_obs_init:]\n",
    "    x1 = torch.tensor(optimizer.data['x1'].values)[n_obs_init:]\n",
    "    y = torch.tensor([item.item() for item in optimizer.data['y'].values])[n_obs_init:]\n",
    "    ax.scatter(x1.flatten(), x0.flatten(), y.flatten(), marker='o', c='C1', alpha=1, s=80, label='BAX Observations', zorder=15)\n",
    "\n",
    "    ax.set_title('Beam Size Surface Samples')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_xlabel('Measurement Parameter')\n",
    "    ax.set_zlabel('Beam Size Squared')\n",
    "\n",
    "    ax.set_ylim(-3, 1)\n",
    "    ax.set_zlim(0)\n",
    "    \n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "\n",
    "    ax.legend()\n",
    "    ax.dist = 12\n",
    "\n",
    "    \n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        torch.set_default_tensor_type(\"torch.cuda.DoubleTensor\")\n",
    "        \n",
    "   \n",
    "\n",
    "    # do a scan (along the tuning dimension) of our emittance predictions\n",
    "    emit_lowers = torch.tensor([])\n",
    "    emit_uppers = torch.tensor([])\n",
    "    emit_meds = torch.tensor([])\n",
    "    for tuning_param in xlin:\n",
    "        x_tuning = tuning_param.reshape(1,-1).to(device)\n",
    "        emits, svr = get_valid_emittance_samples(beam_size_model, \n",
    "                                                 scale_factor, \n",
    "                                                 0.108, \n",
    "                                                 2.26, \n",
    "                                                 x_tuning, \n",
    "                                                 vocs.bounds.T, \n",
    "                                                 meas_dim, \n",
    "                                                 n_samples=100000, \n",
    "                                                 n_steps_quad_scan=10)\n",
    "        emit_lower = torch.quantile(emits, q=0.025, dim=0)\n",
    "        emit_upper = torch.quantile(emits, q=0.975, dim=0)\n",
    "        emit_med = torch.quantile(emits, q=0.5, dim=0)\n",
    "\n",
    "        emit_lowers = torch.cat((emit_lowers, emit_lower))\n",
    "        emit_uppers = torch.cat((emit_uppers, emit_upper))\n",
    "        emit_meds = torch.cat((emit_meds, emit_med))\n",
    "\n",
    "    #get a few batches of n_samples pathwise sample optima\n",
    "    x_stars_all = torch.tensor([])\n",
    "    emit_stars_all = torch.tensor([])\n",
    "    for i in range(5):\n",
    "        algo = optimizer.generator.algorithm\n",
    "        results_dict = algo.get_execution_paths(beam_size_model, torch.tensor(vocs.bounds))[-1]\n",
    "        x_stars = results_dict['x_stars']\n",
    "        emit_stars = results_dict['emit_stars'].detach()\n",
    "        x_stars_all = torch.cat((x_stars_all, x_stars), dim=0)\n",
    "        emit_stars_all = torch.cat((emit_stars_all, emit_stars), dim=0)\n",
    "    \n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    ax = axs[1]\n",
    "    \n",
    "    # plot median emittance curve\n",
    "    medline, = ax.plot(emit_meds.cpu().numpy(), xlin.numpy(), zs=0, zdir='z', c='g', label='Median')\n",
    "    \n",
    "    opt_cross = ax.scatter(emit_stars_all.flatten().cpu(), x_stars_all.flatten().cpu(), zs=0, zdir='z', marker='x', s=40, c='m', alpha=0.5, label='Sample Optima')\n",
    "    \n",
    "    # plot emittance 95% confidence interval as a Poly3DCollection (ordering of vertices matters)\n",
    "    verts = (\n",
    "        [(emit_lowers[i].item(), xlin[i].item(), 0) for i in range(len(xlin))] + \n",
    "        [(emit_uppers[i].item(), xlin[i].item(), 0) for i in range(len(xlin))][::-1]\n",
    "    )\n",
    "    ax.add_collection3d(Poly3DCollection([verts],color='g', edgecolor='None', alpha=0.5)) # Add a polygon instead of fill_between\n",
    "\n",
    "    \n",
    "    ax.set_xlabel('Emittance')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_title('Emittance Measurement Samples')\n",
    "    \n",
    "    ax.set_xlim(0,25)\n",
    "    ax.set_ylim(-3,1)\n",
    "    ax.set_zlim(0,1)\n",
    "\n",
    "    # remove vertical tick marks\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "\n",
    "    orange_patch = mpatches.Patch(color='g', alpha=0.5, label='95% C.I.')\n",
    "    ax.legend(handles=[medline, orange_patch, opt_cross])\n",
    "    ax.dist = 12\n",
    "\n",
    "    \n",
    "    \n",
    "    ax = axs[2]\n",
    "    bins = 10\n",
    "    freq, edges = torch.histogram(x_stars_all.flatten().cpu(), bins=bins, density=True)\n",
    "    for i in range(bins):\n",
    "        uverts = []\n",
    "        lverts = []\n",
    "        uverts += [(freq[i].item(), edges[i].item(), 0), (freq[i].item(), edges[i+1].item(), 0)]\n",
    "        lverts += [(0, edges[i+1].item(), 0), (0, edges[i].item(), 0)]\n",
    "        verts = uverts + lverts\n",
    "        ax.add_collection3d(Poly3DCollection([verts],color='m', edgecolor='k')) # Add a polygon instead of fill_between\n",
    "\n",
    "    ax.set_title('Distribution of Sample Optimal Tuning Parameters')\n",
    "    ax.set_ylabel('Tuning Parameter')\n",
    "    ax.set_xlabel('Frequency')\n",
    "    \n",
    "    ax.set_xlim(0,2)\n",
    "    ax.set_ylim(-3,1)\n",
    "    ax.set_zlim(0,1)\n",
    "    \n",
    "    # remove vertical tick marks\n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # remove tick labels\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_zticklabels([])\n",
    "    \n",
    "    # make the grid lines transparent\n",
    "    ax.xaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.yaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    ax.zaxis._axinfo[\"grid\"]['color'] =  (1,1,1,0)\n",
    "    \n",
    "    ax.dist = 12\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('beamsize-surfaces-with-emittance-1.svg', format='svg')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7907f",
   "metadata": {},
   "source": [
    "# Minimize sample emittance functions produced by current GP beam size model and inspect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ae72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minimize sample emittances (by calling get_exe_paths) and time it\n",
    "start = time.time()\n",
    "algo = optimizer.generator.algorithm\n",
    "X_sample_opt = algo.get_sample_optimal_tuning_configs(beam_size_model, torch.tensor(vocs.bounds))[0]\n",
    "end = time.time()\n",
    "print('get_sample_minima() took', end-start, 'seconds.')\n",
    "\n",
    "\n",
    "\n",
    "print('Average x_tuned =', torch.mean(X_sample_opt, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select sample result\n",
    "\n",
    "sid = 0 #sample index to examine\n",
    "\n",
    "# X_tuned = X_sample_opt[sid].reshape(1,-1)\n",
    "X_tuned = optimizer.generator.algorithm_results['x_stars_all'][sid:sid+1, :]\n",
    "# X_tuned = torch.zeros(1,ndim-1)\n",
    "print('X_tuned =', X_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e040d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot sample emittance minimization result\n",
    "\n",
    "fig, axs = plt.subplots(1, ndim-1)\n",
    "if ndim == 2: axs = [axs]\n",
    "    \n",
    "fig.set_size_inches(3*(ndim-1), 3)\n",
    "\n",
    "for scan_dim in range(ndim-1):\n",
    "    X_tuning_scan = X_tuned.repeat(100,1)\n",
    "    ls = torch.linspace(-3,1,100)\n",
    "    X_tuning_scan[:,scan_dim] = ls\n",
    "    X_meas = torch.linspace(-40,60,3)\n",
    "\n",
    "    emits_sq = post_path_emit_squared(optimizer.generator.algorithm_results['post_paths_cpu'], \n",
    "                              optimizer.generator.algorithm.scale_factor, \n",
    "                              optimizer.generator.algorithm.q_len, \n",
    "                              optimizer.generator.algorithm.distance, \n",
    "                              X_tuning_scan.cpu(), meas_dim, X_meas.cpu(), samplewise=False)[0]\n",
    "        \n",
    "    ax = axs[scan_dim]\n",
    "    \n",
    "    ax.plot(ls.cpu(), (toy_emit_nd(ls.reshape(-1,1))**2).cpu(), c='k', label='Ground truth') #this ground truth isn't exactly the matching cross-section but it should be close\n",
    "\n",
    "    ax.plot(ls.cpu(), emits_sq[sid].detach().cpu(), label='Sample ' + str(sid))\n",
    "    ax.axvline(X_tuned[0,scan_dim].cpu(), c='r', label='Sample optimization result')\n",
    "    ax.axhline(0, c='k', ls='--', label='physical cutoff')\n",
    "    \n",
    "    ax.set_xlabel('tuning param ' + str(scan_dim))\n",
    "    \n",
    "    if scan_dim == 0:\n",
    "        ax.set_ylabel('\"$\\epsilon^{2}$\"')\n",
    "        ax.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f09698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.utils import plot_model_cross_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict = {'x0':[-3.0, 1.0], 'x1': [-40.0, 40.0], 'x2': 1., 'x3': 0.}\n",
    "plot_model_cross_section(beam_size_model, vocs, scan_dict, nx=50, ny=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61d331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
