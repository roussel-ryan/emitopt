{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ac8fe9",
   "metadata": {},
   "source": [
    "# Emittance Sample study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2666c7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b2005f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (algorithms.py, line 890)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\anaconda3\\envs\\xopt-dev\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 23\u001b[1;36m\n\u001b[1;33m    from emitopt.algorithms import GridMinimizeEmitBmag\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\users\\dylan\\slac\\emitopt\\emitopt\\algorithms.py:890\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(run.shape\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "# Ignore all warnings\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "# sys.path.append('C:\\\\Users\\\\Dylan\\\\SLAC') #parent directory containing emitopt module\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from xopt import Xopt\n",
    "from xopt.vocs import VOCS\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "\n",
    "from xopt.evaluator import Evaluator\n",
    "\n",
    "from emitopt.analysis import compute_emit_bmag\n",
    "from emitopt.sampling import draw_product_kernel_post_paths\n",
    "from emitopt.algorithms import GridMinimizeEmitBmag\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d378d",
   "metadata": {},
   "source": [
    "# Use CUDA if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d65ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "# if False:\n",
    "    torch.set_default_tensor_type('torch.cuda.DoubleTensor')\n",
    "    tkwargs = {\"dtype\": torch.double, \"device\": \"cuda\"}\n",
    "    use_cuda = True\n",
    "    print('Using cuda.')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "    use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608db59-6116-47e3-950c-5daccaf4e411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f6014",
   "metadata": {},
   "source": [
    "# Notebook settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4ad68-50a2-42d2-b65d-7170b868678a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ndim = 2 #number of input dimensions\n",
    "noise = False #whether to add noise to the ground-truth beam size function outputs\n",
    "thick_quad = True\n",
    "meas_dim = 1 #input dimension for measurement parameter\n",
    "n_obs_init = 50 #number of random initial observations for GP model\n",
    "n_samples = 10 #number of posterior samples for BAX\n",
    "n_iter = 1 #number of optimization steps for Xopt to take (after acquiring random initial data)\n",
    "rand_seed = 3\n",
    "\n",
    "#random seeds for reproducibility \n",
    "torch.manual_seed(rand_seed)\n",
    "np.random.seed(rand_seed) #only affects initial random observations through Xopt\n",
    "random.seed(rand_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87785524",
   "metadata": {},
   "source": [
    "# Build test function from single-quadrupole optical beam size model \n",
    "Here we define a simple ground-truth beam size function for our optimization problem, where we attempt to find the location in tuning parameter space with minimal emittance. Note that the function \"test_func\" used to evaluate the ground-truth beam size function takes a dictionary as input and returns a dictionary as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468de1ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyemittance.emittance_calc import EmitCalc\n",
    "from pyemittance.load_json_configs import load_configs\n",
    "from pyemittance.simulation import BeamSim\n",
    "\n",
    "CONFIG = load_configs('LCLS2_OTR0H04')\n",
    "CONFIG['beamline_info']\n",
    "\n",
    "q_len = CONFIG['beamline_info']['Lquad']\n",
    "rmat_x = torch.tensor(CONFIG['beamline_info']['rMatx']).reshape(2,2)\n",
    "rmat_y = torch.tensor(CONFIG['beamline_info']['rMaty']).reshape(2,2)\n",
    "print(rmat_x)\n",
    "print(rmat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c052d304",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUNCH_PARAMS0 = {\n",
    "    'total_charge': 50e-12,\n",
    "    'norm_emit_x': 1e-6,\n",
    "    'norm_emit_y': 2e-6,\n",
    "    'beta_x': 10,\n",
    "    'alpha_x': -1,\n",
    "    'beta_y': 11,\n",
    "    'alpha_y': -2,\n",
    "    'energy': 80e6,\n",
    "    'species':'electron'\n",
    "}\n",
    "sim = BeamSim(bunch_params=BUNCH_PARAMS0, beamline_info=CONFIG['beamline_info'])\n",
    "\n",
    "\n",
    "# define variables functions\n",
    "var_names = ['x' + str(i) for i in range(ndim)]\n",
    "meas_param = var_names[meas_dim]\n",
    "\n",
    "from emitopt.utils import get_quad_scale_factor\n",
    "scale_factor = get_quad_scale_factor(E=.08, q_len=q_len)\n",
    "scale = 1.e3\n",
    "\n",
    "def measure_beamsize(input_dict):\n",
    "    x_tuning = torch.tensor([])\n",
    "    for key in input_dict.keys():\n",
    "        if key != str(meas_param):\n",
    "            x_tuning = torch.cat((x_tuning, torch.tensor([input_dict[key]])))\n",
    "    rms_beamsizes0 = np.array(sim.beam_size_meas(input_dict[meas_param]))\n",
    "    detuning_scale = 1. + 1*x_tuning.abs().sum().cpu()\n",
    "    xrms, yrms = detuning_scale * rms_beamsizes0\n",
    "    return {'xrms_sq': (float(xrms)*scale)**2.,\n",
    "            'yrms_sq': (float(yrms)*scale)**2.} # mean-square beam sizes in mm squared\n",
    "\n",
    "\n",
    "# scale_factor = 1.\n",
    "q = torch.linspace(-3,3,11)\n",
    "bs = torch.tensor([np.array(sim.beam_size_meas(v))*scale for v in q.numpy()]).T\n",
    "print(bs)\n",
    "k = scale_factor*q\n",
    "ks = torch.stack((k,-k))\n",
    "rmats = torch.stack((rmat_x, rmat_y))\n",
    "emit, bmag, sig, is_valid = compute_emit_bmag(ks, bs**2, q_len, rmats, thick=True)\n",
    "print(emit[0], emit[1])\n",
    "gt_emit_min = (emit[0]*emit[1]).sqrt()\n",
    "\n",
    "\n",
    "print('Ground truth minimum emit:', gt_emit_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d2c09a",
   "metadata": {},
   "source": [
    "# Construct vocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfbf20e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables = {var_name: [-2,1] for var_name in var_names}\n",
    "variables[meas_param] = [-3,3] #overwrite bounds for measurement parameter to capture minimum of single-quadrupole optical model\n",
    "\n",
    "#construct vocs\n",
    "vocs = VOCS(\n",
    "    variables = variables,\n",
    "    observables = ['xrms_sq', 'yrms_sq'],\n",
    ")\n",
    "\n",
    "print('variable_names =', vocs.variable_names)\n",
    "print('meas_param =', \"'\" + meas_param + \"'\")\n",
    "print('domain =\\n', vocs.bounds.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612bee41-0be7-4ee7-921a-cf51c6c3c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_true_emittance(x, use_bmag=False):\n",
    "    emits = []\n",
    "    bmags = []\n",
    "    for setting in x:\n",
    "        bssx = []\n",
    "        bssy = []\n",
    "        input_dict = {name: float(setting[i]) for i, name in enumerate(vocs.variable_names)}\n",
    "        for v in q.numpy():\n",
    "            input_dict[meas_param] = v\n",
    "            output_dict = measure_beamsize(input_dict)\n",
    "            bssx += [output_dict['xrms_sq']]\n",
    "            bssy += [output_dict['yrms_sq']]\n",
    "        bss = torch.tensor([bssx, bssy])\n",
    "        beta0 = torch.tensor([[10], [11]])\n",
    "        alpha0 = torch.tensor([[-1], [-2]])\n",
    "        emit, bmag, sig, is_valid = compute_emit_bmag(ks, bss, q_len, rmats, beta0=beta0, alpha0=alpha0, thick=True)\n",
    "        emits += [torch.sqrt(emit[0]*emit[1])]\n",
    "        bmags += [torch.sqrt(bmag[0].min()*bmag[1].min())]\n",
    "    res = torch.tensor(emits)\n",
    "    if use_bmag:\n",
    "        res *= torch.tensor(bmags)\n",
    "    return res\n",
    "eval_true_emittance(torch.zeros(1,ndim), use_bmag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4651f47",
   "metadata": {},
   "source": [
    "# Prepare generator options.\n",
    "In this example, we use a specialty covariance module (Matern x Quadratic kernel) for our beam size model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02894212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels import MaternKernel, PolynomialKernel, ScaleKernel\n",
    "from gpytorch.priors.torch_priors import GammaPrior\n",
    "\n",
    "from xopt.generators.bayesian.models.standard import StandardModelConstructor\n",
    "from xopt.generators.bayesian.bax_generator import BaxGenerator\n",
    "from emitopt.algorithms import ScipyMinimizeEmittanceXY\n",
    "\n",
    "# prepare custom covariance module\n",
    "tuning_dims = list(range(vocs.n_variables))\n",
    "tuning_dims.remove(meas_dim)\n",
    "covar_module_x = (MaternKernel(ard_num_dims=len(tuning_dims), \n",
    "                              active_dims=tuning_dims, \n",
    "                              lengthscale_prior=None) * \n",
    "                              PolynomialKernel(power=2, active_dims=[meas_dim])\n",
    "                 )\n",
    "\n",
    "scaled_covar_module_x = ScaleKernel(covar_module_x)#, outputscale_prior=GammaPrior(2.0, 0.15))\n",
    "covar_module_y = (MaternKernel(ard_num_dims=len(tuning_dims), \n",
    "                              active_dims=tuning_dims, \n",
    "                              lengthscale_prior=None) * \n",
    "                              PolynomialKernel(power=2, active_dims=[meas_dim])\n",
    "                 )\n",
    "scaled_covar_module_y =  ScaleKernel(covar_module_y)#, outputscale_prior=GammaPrior(2.0, 0.15))\n",
    "\n",
    "# prepare options for Xopt generator\n",
    "covar_module_dict = {'xrms_sq': scaled_covar_module_x,\n",
    "                     'yrms_sq': scaled_covar_module_y}\n",
    "\n",
    "model_constructor = StandardModelConstructor(covar_modules=covar_module_dict, use_low_noise_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724571ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xopt.numerical_optimizer import LBFGSOptimizer, GridOptimizer\n",
    "numerical_optimizer = LBFGSOptimizer(\n",
    "                                    n_restarts=20,\n",
    "                                    max_time=2)\n",
    "# numerical_optimizer = GridOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd586df8",
   "metadata": {},
   "source": [
    "# Construct generator, evaluator, Xopt objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4289b-55c6-49e4-b749-a83da9de16f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class DifferentialEvolutionEmitBmag(GridMinimizeEmitBmag):\n",
    "#     name = \"DifferentialEvolutionEmitBmag\"\n",
    "\n",
    "#     def get_execution_paths(self, model: ModelList, bounds: Tensor, tkwargs=None, verbose=False):\n",
    "#         if not (self.x_key or self.y_key):\n",
    "#             raise ValueError(\"must provide a key for x, y, or both.\")\n",
    "#         if (self.x_key and self.rmat_x is None) or (self.y_key and self.rmat_y is None):\n",
    "#             raise ValueError(\"must provide rmat for each transverse dimension (x/y) being modeled.\")\n",
    "    \n",
    "#         tkwargs = tkwargs if tkwargs else {\"dtype\": torch.double, \"device\": \"cpu\"}\n",
    "\n",
    "#         temp_id = self.meas_dim + 1\n",
    "#         tuning_domain = torch.cat((bounds.T[: self.meas_dim], bounds.T[temp_id:]))\n",
    "\n",
    "#         tuning_bounds = tuning_domain.T\n",
    "        \n",
    "#         cpu_models = [copy.deepcopy(m).cpu() for m in model.models]\n",
    "\n",
    "#         sample_funcs_list = []\n",
    "#         for cpu_model in cpu_models:\n",
    "#             if type(cpu_model.covar_module.base_kernel) == ProductKernel:\n",
    "#                 sample_funcs = draw_product_kernel_post_paths(cpu_model, n_samples=self.n_samples)\n",
    "#             if type(cpu_model.covar_module.base_kernel) == MaternKernel:\n",
    "#                 sample_funcs = draw_matheron_paths(cpu_model, sample_shape=torch.Size([self.n_samples]))\n",
    "#             sample_funcs_list += [sample_funcs]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623bc33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from emitopt.algorithms import DifferentialEvolutionEmitBmag\n",
    "\n",
    "#Prepare Algorithm\n",
    "algo_kwargs = {\n",
    "        'x_key': 'xrms_sq',\n",
    "        'y_key': 'yrms_sq',\n",
    "        'scale_factor': scale_factor,\n",
    "        'q_len': q_len,\n",
    "        'rmat_x': rmat_x,\n",
    "        'rmat_y': rmat_y,\n",
    "        'twiss0_x': torch.tensor([10., -1.]),\n",
    "        'twiss0_y': torch.tensor([11., -2.]),\n",
    "        'n_samples': n_samples,\n",
    "        'meas_dim': meas_dim,\n",
    "        'n_steps_measurement_param': 3,\n",
    "        'thick_quad': thick_quad,\n",
    "        'n_grid_points': 3,\n",
    "        'use_bmag': True,\n",
    "}\n",
    "algo = DifferentialEvolutionEmitBmag(**algo_kwargs)\n",
    "# algo = GridMinimizeEmitBmag(**algo_kwargs)\n",
    "# algo = ScipyMinimizeEmittanceXY(**algo_kwargs)\n",
    "\n",
    "#construct BAX generator\n",
    "generator = BaxGenerator(vocs=vocs, \n",
    "                         gp_constructor=model_constructor, \n",
    "                         numerical_optimizer=numerical_optimizer,\n",
    "                         algorithm=algo, \n",
    "                         use_cuda=use_cuda)\n",
    "\n",
    "#construct evaluator\n",
    "evaluator = Evaluator(function=measure_beamsize)\n",
    "\n",
    "#construct Xopt optimizer\n",
    "optimizer = Xopt(evaluator=evaluator, generator=generator, vocs=vocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae84fc5",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3553f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call X.random_evaluate() to generate random initial points and evaluate on test_func\n",
    "optimizer.random_evaluate(n_obs_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f999a8-0b0c-4802-bcbd-c096d45a2765",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian.visualize import visualize_generator_model\n",
    "optimizer.generator.train_model()\n",
    "visualize_generator_model(optimizer.generator, \n",
    "                          variable_names=['x0','x1'], \n",
    "                            reference_point={'x0':torch.tensor([0.]),\n",
    "                                             'x1':torch.tensor([0.]),\n",
    "                                            # 'x2':torch.tensor([0.]),\n",
    "                                            #  'x3':torch.tensor([0.]),\n",
    "                                             # 'x4':torch.tensor([0.]),\n",
    "                                             # 'x5':torch.tensor([0.]),\n",
    "                                             # 'x6':torch.tensor([0.]),\n",
    "                                             # 'x7':torch.tensor([0.]),\n",
    "                                             # 'x8':torch.tensor([0.]),\n",
    "                                            },\n",
    "                          show_acquisition=False)\n",
    "visualize_generator_model(optimizer.generator, \n",
    "                          variable_names=['x1'], \n",
    "                            reference_point={'x0':torch.tensor([0.]),\n",
    "                                             'x1':torch.tensor([0.]),\n",
    "                                            # 'x2':torch.tensor([0.]),\n",
    "                                            #  'x3':torch.tensor([0.]),\n",
    "                                             # 'x4':torch.tensor([0.]),\n",
    "                                             # 'x5':torch.tensor([0.]),\n",
    "                                             # 'x6':torch.tensor([0.]),\n",
    "                                             # 'x7':torch.tensor([0.]),\n",
    "                                             # 'x8':torch.tensor([0.]),\n",
    "                                            },\n",
    "                          show_acquisition=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588657b7-5670-4789-95b8-b48a033af526",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(100, ndim)\n",
    "x[:,0] = torch.linspace(*vocs.bounds.T[0], 100)\n",
    "plt.plot(x[:,0], eval_true_emittance(x, use_bmag=True), c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b271a99-63e1-41b8-be6b-bf4eebbd2a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54021eb-d483-437f-adc5-92559b332336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from xopt.generators.bayesian.bax.visualize import visualize_virtual_objective\n",
    "model = optimizer.generator.train_model()\n",
    "\n",
    "# for i in range(10):\n",
    "start = time.time()\n",
    "fig, ax = visualize_virtual_objective(optimizer.generator, \n",
    "                            variable_names=['x0'],\n",
    "                            reference_point={'x0':torch.tensor([0.]),\n",
    "                                             'x1':torch.tensor([0.]),\n",
    "                                            # 'x2':torch.tensor([0.]),\n",
    "                                            #  'x3':torch.tensor([0.]),\n",
    "                                            #  'x4':torch.tensor([0.]),\n",
    "                                            #  'x5':torch.tensor([0.]),\n",
    "                                            #  'x6':torch.tensor([0.]),\n",
    "                                            #  'x7':torch.tensor([0.]),\n",
    "                                            #  'x8':torch.tensor([0.]),\n",
    "                                            },\n",
    "                            n_grid=100,\n",
    "                            n_samples=1,\n",
    "                            show_samples=True,\n",
    "                            # kwargs={'use_bmag':False},\n",
    "                                     )\n",
    "print(time.time()-start)\n",
    "x = torch.zeros(100, ndim)\n",
    "x[:,0] = torch.linspace(*vocs.bounds.T[0], 100)\n",
    "plt.plot(x[:,0], eval_true_emittance(x, use_bmag=True), c='k')\n",
    "# plt.ylim(top=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caee0af-886b-4936-8298-8fc1ab7cb3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from emitopt.sampling import draw_product_kernel_post_paths\n",
    "import copy\n",
    "\n",
    "bounds = torch.from_numpy(vocs.bounds)\n",
    "\n",
    "\n",
    "# sample_funcs_list =[]\n",
    "# cpu_models = [copy.deepcopy(m).cpu() for m in model.models]\n",
    "# for cpu_model in cpu_models:\n",
    "#     sample_funcs = draw_product_kernel_post_paths(cpu_model, n_samples=1)\n",
    "#     sample_funcs_list += [sample_funcs]\n",
    "\n",
    "sample_funcs_list = optimizer.generator.algorithm.results['sample_funcs_list']\n",
    "\n",
    "def wrapped_virtual_objective(x):\n",
    "    x = torch.from_numpy(x)\n",
    "    start = time.time()\n",
    "    res = algo.evaluate_virtual_objective(sample_funcs_list, x.T.unsqueeze(0), bounds)\n",
    "    print(time.time() - start)\n",
    "    return res[0,:].numpy()\n",
    "    # return res[0,0]\n",
    "\n",
    "# from emitopt.algorithms import unif_random_sample_domain\n",
    "# x0 = unif_random_sample_domain(1, vocs.bounds.T).flatten()\n",
    "# print(wrapped_virtual_objective(x0))\n",
    "# torch.autograd.functional.jacobian(wrapped_virtual_objective, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb1a656-4582-4eee-97e0-3b1a3f43076b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution, shgo, dual_annealing, minimize\n",
    "\n",
    "opt_bounds = vocs.bounds.T\n",
    "opt_bounds[algo.meas_dim] = [0,0]\n",
    "\n",
    "start = time.time()\n",
    "res = differential_evolution(wrapped_virtual_objective, bounds=opt_bounds, vectorized=True, polish=False, popsize=50, maxiter=10, seed=1)\n",
    "# res = shgo(wrapped_virtual_objective, bounds=opt_bounds)\n",
    "# res = dual_annealing(wrapped_virtual_objective, bounds=opt_bounds, seed=1)\n",
    "\n",
    "# from emitopt.algorithms import unif_random_sample_domain\n",
    "# x0 = unif_random_sample_domain(1, vocs.bounds.T).flatten().numpy()\n",
    "# res = minimize(wrapped_virtual_objective, x0, bounds=opt_bounds)\n",
    "\n",
    "print(time.time() - start)\n",
    "print(res.fun)\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ffcb29-6887-415a-8800-166d3b0d48ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb6585-322c-4986-8508-be8f9f792edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(ndim):\n",
    "    if i == meas_dim:\n",
    "        continue\n",
    "    x = torch.from_numpy(res.x).repeat(100,1)\n",
    "    x[:,i] = torch.linspace(-2, 1, 100)\n",
    "    x = x.repeat(1, 1, 1)\n",
    "    vobj = algo.evaluate_virtual_objective(sample_funcs_list, x, bounds)\n",
    "    \n",
    "    plt.plot(x[:,:,i].T, vobj.T, c='C0')\n",
    "    plt.scatter([res.x[i]], [res.fun], c='r', marker='x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90229f1-99d1-4874-9a9a-bb8cb59d4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmag = algo.results['bmag']\n",
    "bmag_mean = (bmag[...,0] * bmag[...,1]).sqrt()\n",
    "bmag_min, bmag_min_id = torch.min(bmag_mean, dim=-1)\n",
    "plt.plot(x[:,:,0].T,bmag_min.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24fb03a-eba8-442e-81d4-2a0b1828d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbf136-7f1e-4d6f-964c-f0a9ed634cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_funcs_list = []\n",
    "for cpu_model in cpu_models:\n",
    "    sample_funcs = draw_product_kernel_post_paths(cpu_model, n_samples=10)\n",
    "    sample_funcs_list += [sample_funcs]\n",
    "\n",
    "from emitopt.algorithms import unif_random_sample_domain\n",
    "x0 = unif_random_sample_domain(1000, vocs.bounds.T)\n",
    "start = time.time()\n",
    "algo.evaluate_virtual_objective(sample_funcs_list, x0.reshape(10, 100, -1), bounds)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cedc06-9b0e-4aba-88af-9b338ed6bec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from emitopt.utils import x_tuning_to_dict, get_bax_optimum\n",
    "# print(optimizer.generator.algorithm_results['x_tuning_best'])\n",
    "# x_tuning_best = optimizer.generator.algorithm_results['x_tuning_best'].mean(dim=0)\n",
    "# print(x_tuning_best)\n",
    "# reference_point = get_bax_optimum(optimizer.generator)\n",
    "# print(reference_point)\n",
    "# target_point = x_tuning_to_dict(optimizer.generator, x_tuning = torch.tensor([[0]]))\n",
    "# print(target_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1609dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emitopt.visualize import plot_virtual_measurement_scan\n",
    "fig, ax, best_q = plot_virtual_measurement_scan(optimizer, reference_point, n_samples=10)\n",
    "ax[0].set_ylim(top=1)\n",
    "ax[1].set_ylim(top=3, bottom=0.9)\n",
    "ax[0].axhline(0, c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2472856-ba66-4813-9516-222dbf1afe08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
